# Release Notes - v0.11.2 Production Issue Fixes

**Release Date**: 2026-02-06
**Type**: Patch (LLM hallucination prevention + deployment pipeline fix)

---

## 1. Summary

This release addresses production issues discovered after v0.11.1 deployment, focusing on LLM response reliability and data quality.

**Root Cause**: Render Auto-Deploy was OFF, so v0.11.1 code was committed but not deployed to production. After enabling Auto-Deploy, the following issues were identified and fixed.

**Fixes (3 issues)**:
1. [P0] Chat "knowledge graph not being initialized" — LLM hallucination
2. [P1] "0 concepts in 5 clusters" — Stale data from old code
3. [P2] English-only responses — Korean text in greeting removed

---

## 2. Bug Fixes

### 2.1 [P0] LLM Hallucination Prevention (Issue A)

**Symptom**: "Research gap analysis" query returns "knowledge graph not being initialized" despite GraphStore being properly initialized.

**Root Cause**: LLM (Groq llama) ignored provided gap data and fabricated an error message. Contributing factors:
- No system prompt rule enforcing data usage
- Cluster names truncated to 2 characters in context
- Temperature 0.3 allowed creative deviation

**Fix** (dual-layer defense):
1. `reasoning_agent.py`: Added CRITICAL RULES to system prompt ("NEVER claim graph is unavailable when data is present"), reduced temperature 0.3→0.1, show full cluster names in gap context
2. `response_agent.py`: Added hallucination detection guard — 7 phrase patterns (e.g., "not initialized", "currently unavailable") trigger fallback to actual DB data from reasoning_result

**Files**:
- `backend/agents/reasoning_agent.py`
- `backend/agents/response_agent.py`

### 2.2 [P1] Gap Cluster Label & Size Fix (Issue B)

**Symptom**: GapPanel shows 5 clusters but all display "0 concepts" with generic "Cluster N" labels.

**Root Cause**: Existing gap data was generated by old code that didn't populate cluster names or concept_ids properly.

**Fix** (committed in 9b2958e, included in this release):
- 3-tier label generation: cluster.name → top 3 concept names → "Cluster N" fallback
- Requires gap refresh (`POST /api/graph/gaps/{project_id}/refresh`) to regenerate cluster data with new code

**File**:
- `backend/routers/graph.py`

### 2.3 [P2] English-Only Greeting Response (Issue A supplement)

**Symptom**: Orchestrator greeting response contained Korean text mixed with English.

**Fix**: Converted greeting response to English-only.

**File**:
- `backend/agents/orchestrator.py`

---

## 3. Deployment Pipeline Fix

| Item | Before | After |
|------|--------|-------|
| Render Auto-Deploy | OFF | ON (user-activated) |
| Deploy trigger | Manual via Render Dashboard | Automatic on git push |

**Recurrence Prevention**: With Auto-Deploy ON, `git push origin main` triggers automatic deployment to production.

---

## 4. Verification Results

| Issue | Status | Evidence |
|-------|--------|----------|
| A: Chat hallucination | Fixed (code) | Dual-layer guard: prompt rules + response pattern matching |
| B: Cluster labels | Fixed (verified) | Gap refresh returns 5 clusters with concept-based labels, sizes 11-153 |
| C: Topics button | Deployed (v0.11.1) | Vercel auto-deployed, needs browser verification |
| D: Panel drag | Deployed (v0.11.1) | Vercel auto-deployed, needs browser verification |
| E: Node jitter | Deployed (v0.11.1) | Vercel auto-deployed, needs browser verification |

- `python3 -m py_compile`: All 3 backend files pass
- `GET /health`: Backend healthy (DB connected, Groq LLM configured)
- Gap refresh: 5 clusters, 10 gaps, meaningful labels

---

## 5. Changed Files Summary

| File | Change Type | Issue |
|------|------------|-------|
| `backend/agents/reasoning_agent.py` | Modified | #1 LLM hallucination prevention |
| `backend/agents/response_agent.py` | Modified | #1 Hallucination response guard |
| `backend/agents/orchestrator.py` | Modified | #3 English-only greeting |
| `GAP_CLUSTER_FIX_SUMMARY.md` | Deleted | Cleanup temp file |

---

## 6. Known Limitations

1. **Cluster 2 empty labels**: One cluster (11 concepts) has empty concept names in DB — data quality issue from entity extraction, not a code bug
2. **LLM quality general**: Groq llama model may occasionally produce unexpected responses — long-term monitoring recommended
3. **Render free tier**: Cold start and timeout possibilities remain

---

## 7. Post-Deployment Actions

1. Verify Render has deployed commit `f8a821d` (or later)
2. Run gap refresh: `POST /api/graph/gaps/eb53a24b-0630-474e-a276-8bf93f8a79a4/refresh`
3. Test chat: Ask "Research gap analysis" — should return data-based response
4. Verify frontend issues C/D/E in browser at https://schola-rag-graph.vercel.app
