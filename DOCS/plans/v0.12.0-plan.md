# v0.12.0 Release Plan — LLM Cluster Labels + Paper Recommendations + Report Export

> **Version**: 0.12.0
> **Base**: v0.11.2
> **Difficulty**: Medium
> **Estimated Commits**: 4-5
> **Prerequisite**: None (builds on existing v0.11.x infrastructure)

---

## Objective

Deliver three tightly scoped features that strengthen the **Gap Analysis** pipeline:

1. **Phase 1** — LLM-summarized cluster labels (3-5 words instead of 30+)
2. **Phase 2** — Gap-based paper recommendations via Semantic Scholar (MVP)
3. **Phase 3** — Gap analysis report export as Markdown

These three features together create the core "portfolio demo moment": a researcher discovers gaps, gets paper recommendations, and exports a ready-to-use report.

---

## Phase 1: LLM-Summarized Cluster Labels

### Problem

Current cluster labels are raw keyword concatenations (e.g., `"217 hr practitioners / four studies / algorithmic decision"`), which are too long and uninformative in the UI.

### Goal

Replace with concise 3-5 word topic labels (e.g., `"HR Practitioner Studies"`) using LLM summarization with robust fallback.

### Changed Files

| File | Change |
|------|--------|
| `backend/graph/gap_detector.py` | Add `_generate_cluster_label()` async method to `GapDetector` class |
| `backend/routers/graph.py` | Call label generation during gap refresh (inside `refresh_gap_analysis`) |

### Implementation Detail

#### `gap_detector.py` — Add `_generate_cluster_label()` method

Insert after the existing `_generate_summary()` method (line ~873):

```python
async def _generate_cluster_label(self, keywords: list[str]) -> str:
    """LLM으로 클러스터 키워드를 3-5 단어 토픽 레이블로 요약.
    캐시 + 폴백 + timeout 적용."""
    if not self.llm or not keywords:
        return " / ".join(keywords[:3])  # Fallback 1: No LLM

    try:
        prompt = (
            "Summarize these academic concepts into a 3-5 word topic label:\n"
            f"{', '.join(keywords[:10])}\n\n"
            "Respond with ONLY the label, nothing else."
        )
        label = await asyncio.wait_for(
            self.llm.generate(prompt=prompt, max_tokens=20, temperature=0.0),
            timeout=5.0  # 5-second timeout per label
        )
        result = label.strip().strip('"').strip("'")
        if len(result) < 3 or len(result) > 60:
            return " / ".join(keywords[:3])  # Fallback 2: Abnormal response
        return result
    except (asyncio.TimeoutError, Exception) as e:
        logger.warning(f"LLM label generation failed: {e}")
        return " / ".join(keywords[:3])  # Fallback 3: Error
```

> **Note**: Requires `import asyncio` at the top of gap_detector.py (already present).

#### `graph.py` — Call during gap refresh

In `refresh_gap_analysis()` (line ~1042), after clusters are built and before storing to DB, add sequential LLM label calls:

```python
# After cluster_concepts() returns and before DB insert
# Generate LLM labels for each cluster (sequential to respect rate limits)
for cluster in clusters:
    if cluster.keywords:
        cluster.name = await gap_detector._generate_cluster_label(cluster.keywords)
```

### Key Design Decisions

- **Sequential calls** (not parallel) → safe for LLM rate limits
- **5-second timeout** per label → 5 clusters max 25 seconds
- **3-tier fallback**: LLM unavailable → abnormal response → exception
- **No separate cache layer** — labels are persisted in `concept_clusters.label` column in DB

### Reused Code

- `GapDetector.llm` provider — already injected in `refresh_gap_analysis()` via `LLMProvider`
- `concept_clusters` table `label` column — already exists in schema

### Acceptance Criteria

| # | Criterion | Verification |
|---|-----------|-------------|
| 1 | **Response time**: Gap refresh total < 30 seconds (including LLM labels) | `time curl -X POST .../api/graph/gaps/{id}/refresh` |
| 2 | **Fallback**: LLM failure → automatic keyword-join fallback (no error shown) | Kill LLM provider, verify labels still appear |
| 3 | **UI**: GapPanel displays 3-5 word labels instead of long keyword strings | Visual check in browser |

### Commit

```
feat(gaps): LLM-summarized cluster labels with cache and fallback
```

---

## Phase 2: Gap-Based Paper Recommendations (MVP)

### Scope

- Semantic Scholar search only (no OpenAlex)
- No server-side caching
- Simple card UI in GapPanel

### Reused Code

| Source | What |
|--------|------|
| `backend/integrations/semantic_scholar.py` → `SemanticScholarClient.search_papers()` | Paper search with rate limiting (lines 252-305) |
| `backend/integrations/semantic_scholar.py` → `SemanticScholarClient._rate_limit()` | Built-in rate limiter (lines 195-211) |
| `backend/routers/graph.py` → `structural_gaps` table queries | Gap data access pattern (lines 929-968) |
| `frontend/lib/api.ts` → `ApiClient.request()` | Auth + retry wrapper (lines 106-162) |

### Changed Files

| File | Change |
|------|--------|
| `backend/routers/graph.py` | Add `GET /api/graph/gaps/{project_id}/recommendations` endpoint |
| `frontend/components/graph/GapPanel.tsx` | Add "Find Papers" button + recommendation cards UI |
| `frontend/lib/api.ts` | Add `getGapRecommendations()` method |

### Implementation Detail

#### `graph.py` — New endpoint

Insert after the existing `/gaps/{gap_id}/questions` endpoint (line ~1630):

```python
class RecommendedPaperResponse(BaseModel):
    """A recommended paper from Semantic Scholar."""
    title: str
    year: Optional[int] = None
    citation_count: int = 0
    url: Optional[str] = None
    abstract_snippet: str = ""


class GapRecommendationsResponse(BaseModel):
    """Paper recommendations for a research gap."""
    gap_id: str
    query_used: str
    papers: List[RecommendedPaperResponse]


@router.get("/gaps/{project_id}/recommendations", response_model=GapRecommendationsResponse)
async def get_gap_recommendations(
    project_id: UUID,
    gap_id: str = Query(..., description="Gap UUID from analysis"),
    limit: int = Query(5, ge=1, le=10),
    database=Depends(get_db),
    current_user: Optional[User] = Depends(require_auth_if_configured),
):
    """Recommend papers that could bridge a research gap."""
    await verify_project_access(database, project_id, current_user, "access")

    # 1. Get gap data from DB
    gap = await database.fetchrow(
        """SELECT bridge_candidates, cluster_a_names, cluster_b_names
           FROM structural_gaps
           WHERE id = $1 AND project_id = $2""",
        gap_id, str(project_id),
    )
    if not gap:
        raise HTTPException(404, "Gap not found")

    # 2. Build search query from bridge concepts + cluster keywords
    bridge = (gap["bridge_candidates"] or [])[:3]
    kw_a = (gap["cluster_a_names"] or [])[:2]
    kw_b = (gap["cluster_b_names"] or [])[:2]
    query = " ".join(bridge + kw_a + kw_b)

    if not query.strip():
        return GapRecommendationsResponse(gap_id=gap_id, query_used="", papers=[])

    # 3. Search Semantic Scholar (reuse existing client)
    from integrations.semantic_scholar import SemanticScholarClient
    async with SemanticScholarClient() as client:
        papers = await client.search_papers(query=query, limit=limit)

    # 4. Format response
    return GapRecommendationsResponse(
        gap_id=gap_id,
        query_used=query,
        papers=[
            RecommendedPaperResponse(
                title=p.title,
                year=p.year,
                citation_count=p.citation_count,
                url=f"https://doi.org/{p.doi}" if p.doi else
                    (f"https://arxiv.org/abs/{p.arxiv_id}" if p.arxiv_id else None),
                abstract_snippet=(p.abstract or "")[:200],
            )
            for p in papers
        ],
    )
```

#### `api.ts` — New method

Add after `generateResearchQuestions()` (line ~535):

```typescript
// Paper Recommendations for Gaps
async getGapRecommendations(
  projectId: string,
  gapId: string,
  limit: number = 5
): Promise<{
  gap_id: string;
  query_used: string;
  papers: Array<{
    title: string;
    year: number | null;
    citation_count: number;
    url: string | null;
    abstract_snippet: string;
  }>;
}> {
  const params = new URLSearchParams({
    gap_id: gapId,
    limit: limit.toString(),
  });
  return this.request(
    `/api/graph/gaps/${projectId}/recommendations?${params}`
  );
}
```

#### `GapPanel.tsx` — UI changes

Add state and handler:

```typescript
// New state (add alongside existing state declarations)
const [recommendations, setRecommendations] = useState<Record<string, {
  papers: Array<{ title: string; year: number | null; citation_count: number; url: string | null; abstract_snippet: string }>;
  query_used: string;
}>>({});
const [loadingRecsFor, setLoadingRecsFor] = useState<string | null>(null);

// Handler
const handleFindPapers = useCallback(async (gapId: string) => {
  if (loadingRecsFor) return;
  setLoadingRecsFor(gapId);
  try {
    const result = await api.getGapRecommendations(projectId, gapId, 5);
    setRecommendations(prev => ({ ...prev, [gapId]: result }));
  } catch (error) {
    console.error('Failed to fetch recommendations:', error);
  } finally {
    setLoadingRecsFor(null);
  }
}, [loadingRecsFor, projectId]);
```

Add button in the expanded gap content area (after the Bridge Ideas section, before Research Questions):

```tsx
{/* Find Papers Button */}
<div className="pt-2 border-t border-ink/5 dark:border-paper/5">
  <button
    onClick={() => handleFindPapers(gap.id)}
    disabled={loadingRecsFor === gap.id}
    className="w-full py-2 px-4 font-mono text-xs uppercase tracking-wider
      bg-accent-teal/10 hover:bg-accent-teal/20 text-accent-teal
      border border-accent-teal/30 transition-colors
      flex items-center justify-center gap-2"
  >
    {loadingRecsFor === gap.id ? (
      <><Loader2 className="w-4 h-4 animate-spin" /> Searching...</>
    ) : (
      <><BookOpen className="w-4 h-4" /> Find Papers</>
    )}
  </button>
</div>

{/* Recommendation Cards */}
{recommendations[gap.id] && (
  <div className="space-y-2 mt-2">
    {recommendations[gap.id].papers.map((paper, idx) => (
      <div key={idx} className="p-3 border border-ink/10 dark:border-paper/10 bg-surface/5">
        <a
          href={paper.url || '#'}
          target="_blank"
          rel="noopener noreferrer"
          className="text-xs font-medium text-accent-teal hover:underline block mb-1"
        >
          {paper.title}
        </a>
        <div className="flex items-center gap-3 font-mono text-xs text-muted">
          {paper.year && <span>{paper.year}</span>}
          <span>{paper.citation_count} citations</span>
        </div>
        {paper.abstract_snippet && (
          <p className="text-xs text-muted mt-1 line-clamp-2">{paper.abstract_snippet}</p>
        )}
      </div>
    ))}
  </div>
)}
```

> **Note**: Add `BookOpen` to the lucide-react imports at the top of GapPanel.tsx.

### Acceptance Criteria

| # | Criterion | Verification |
|---|-----------|-------------|
| 1 | **Response time**: Recommendations API < 10 seconds | `time curl ".../api/graph/gaps/{pid}/recommendations?gap_id={id}&limit=5"` |
| 2 | **Fallback**: API failure → "Recommendations unavailable" message (no app crash) | Disconnect network, click "Find Papers" |
| 3 | **UI**: Paper cards show title, year, citation count, and clickable DOI link | Visual check in browser |

### Commit

```
feat(gaps): paper recommendations for research gaps via Semantic Scholar
```

---

## Phase 3: Gap Analysis Report Export

### Changed Files

| File | Change |
|------|--------|
| `backend/routers/graph.py` | Add `GET /api/graph/gaps/{project_id}/export` endpoint |
| `frontend/components/graph/GapPanel.tsx` | Add "Export Report" button at panel bottom |
| `frontend/lib/api.ts` | Add `exportGapReport()` method |

### Implementation Detail

#### `graph.py` — Export endpoint

Insert after the recommendations endpoint:

```python
@router.get("/gaps/{project_id}/export")
async def export_gap_report(
    project_id: UUID,
    format: str = Query("markdown", pattern="^(markdown)$"),
    database=Depends(get_db),
    current_user: Optional[User] = Depends(require_auth_if_configured),
):
    """Export gap analysis as downloadable Markdown report."""
    await verify_project_access(database, project_id, current_user, "access")

    from fastapi.responses import StreamingResponse
    from datetime import datetime
    import io

    # 1. Get project info
    project = await database.fetchrow(
        "SELECT name, research_question FROM projects WHERE id = $1",
        project_id,
    )
    if not project:
        raise HTTPException(404, "Project not found")

    # 2. Get clusters
    cluster_rows = await database.fetch(
        """SELECT cluster_id, label, size, concept_names
           FROM concept_clusters WHERE project_id = $1
           ORDER BY cluster_id""",
        str(project_id),
    )

    # 3. Get gaps
    gap_rows = await database.fetch(
        """SELECT cluster_a_id, cluster_b_id, cluster_a_names, cluster_b_names,
                  gap_strength, bridge_candidates, research_questions
           FROM structural_gaps WHERE project_id = $1
           ORDER BY gap_strength DESC""",
        str(project_id),
    )

    if not cluster_rows and not gap_rows:
        raise HTTPException(
            404,
            "No gap analysis data. Run gap detection first."
        )

    # 4. Build cluster label lookup
    cluster_labels = {}
    for row in cluster_rows:
        cluster_labels[row["cluster_id"]] = row["label"] or f"Cluster {row['cluster_id'] + 1}"

    # 5. Generate Markdown
    lines = [
        f"# Research Gap Analysis Report",
        f"",
        f"**Project**: {project['name']}",
    ]
    if project.get("research_question"):
        lines.append(f"**Research Question**: {project['research_question']}")
    lines.extend([
        f"**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
        f"**Clusters**: {len(cluster_rows)} | **Gaps**: {len(gap_rows)}",
        f"",
        f"---",
        f"",
        f"## Cluster Overview",
        f"",
        f"| # | Name | Size | Top Concepts |",
        f"|---|------|------|-------------|",
    ])

    for row in cluster_rows:
        cid = row["cluster_id"]
        label = cluster_labels.get(cid, f"Cluster {cid + 1}")
        size = row["size"]
        concepts = ", ".join((row["concept_names"] or [])[:5])
        lines.append(f"| {cid + 1} | {label} | {size} | {concepts} |")

    lines.extend(["", "---", "", "## Research Gaps", ""])

    for i, row in enumerate(gap_rows):
        a_label = cluster_labels.get(row["cluster_a_id"], f"Cluster {row['cluster_a_id'] + 1}")
        b_label = cluster_labels.get(row["cluster_b_id"], f"Cluster {row['cluster_b_id'] + 1}")
        strength = row["gap_strength"] or 0

        lines.extend([
            f"### Gap {i + 1}: {a_label} ↔ {b_label}",
            f"",
            f"- **Gap Strength**: {strength:.1%}",
            f"- **Cluster A Concepts**: {', '.join((row['cluster_a_names'] or [])[:5])}",
            f"- **Cluster B Concepts**: {', '.join((row['cluster_b_names'] or [])[:5])}",
        ])

        bridge = row.get("bridge_candidates") or []
        if bridge:
            lines.append(f"- **Bridge Concepts**: {', '.join(bridge[:5])}")

        questions = row.get("research_questions") or []
        if questions:
            lines.extend(["", "**AI-Generated Research Questions**:", ""])
            for q in questions:
                lines.append(f"1. {q}")

        lines.extend(["", "---", ""])

    lines.extend([
        "",
        f"*Report generated by ScholaRAG Graph v0.12.0*",
    ])

    report = "\n".join(lines)
    buffer = io.BytesIO(report.encode("utf-8"))

    safe_name = project["name"].replace(" ", "_")[:30]
    return StreamingResponse(
        buffer,
        media_type="text/markdown",
        headers={
            "Content-Disposition": f'attachment; filename="gap_analysis_{safe_name}.md"'
        },
    )
```

#### `api.ts` — Export method

Add after `getGapRecommendations()`:

```typescript
// Gap Report Export
async exportGapReport(projectId: string): Promise<void> {
  const authHeaders = await this.getAuthHeaders();
  const response = await fetch(
    `${this.baseUrl}/api/graph/gaps/${projectId}/export?format=markdown`,
    { headers: { ...authHeaders } }
  );
  if (!response.ok) {
    const error = await response.json().catch(() => ({}));
    throw new Error(error.detail || `Export failed: ${response.status}`);
  }
  const blob = await response.blob();
  const url = window.URL.createObjectURL(blob);
  const a = document.createElement('a');
  a.href = url;
  a.download = response.headers.get('content-disposition')
    ?.split('filename=')[1]?.replace(/"/g, '') || 'gap_analysis.md';
  document.body.appendChild(a);
  a.click();
  a.remove();
  window.URL.revokeObjectURL(url);
}
```

#### `GapPanel.tsx` — Export button

Add at the bottom of the panel, after the "Cluster Overview" section and before the closing `</>`:

```tsx
{/* Export Report Button */}
{gaps.length > 0 && (
  <div className="p-4 border-t border-ink/10 dark:border-paper/10">
    <button
      onClick={async () => {
        try {
          await api.exportGapReport(projectId);
        } catch (error) {
          console.error('Export failed:', error);
        }
      }}
      className="w-full py-2.5 px-3 bg-surface/10 hover:bg-surface/20
        font-mono text-xs text-ink dark:text-paper uppercase tracking-wider
        transition-colors flex items-center justify-center gap-2
        border border-ink/10 dark:border-paper/10"
    >
      <Download className="w-4 h-4" />
      Export Report
    </button>
  </div>
)}
```

> **Note**: Add `Download` to the lucide-react imports at the top of GapPanel.tsx.

### Acceptance Criteria

| # | Criterion | Verification |
|---|-----------|-------------|
| 1 | **Response time**: Report generation < 3 seconds | `time curl -o report.md ".../api/graph/gaps/{pid}/export"` |
| 2 | **Fallback**: No gap data → 404 with "No gap analysis data. Run gap detection first." | Request export before running gap detection |
| 3 | **UI**: `.md` file downloads and renders correctly in any Markdown viewer | Download file, open in VS Code / GitHub preview |

### Commit

```
feat(export): gap analysis Markdown report download
```

---

## Commit Strategy

| Order | Message | Files |
|-------|---------|-------|
| 1 | `feat(gaps): LLM-summarized cluster labels with cache and fallback` | `gap_detector.py`, `graph.py` |
| 2 | `feat(gaps): paper recommendations for research gaps via Semantic Scholar` | `graph.py`, `GapPanel.tsx`, `api.ts` |
| 3 | `feat(export): gap analysis Markdown report download` | `graph.py`, `GapPanel.tsx`, `api.ts` |
| 4 | `docs(v0.12.0): release notes, SDD, TDD updates` | `RELEASE_NOTES_v0.12.0.md`, `DOCS/` |

---

## Integration Verification

```bash
# 1. Gap refresh → LLM labels
curl -X POST .../api/graph/gaps/{project_id}/refresh
curl .../api/graph/gaps/{project_id}/analysis
# → cluster labels are 3-5 words

# 2. Paper recommendations
curl ".../api/graph/gaps/{project_id}/recommendations?gap_id={id}&limit=5"
# → papers array with 5 items, each having title/year/citation_count

# 3. Report export
curl -o report.md ".../api/graph/gaps/{project_id}/export"
# → valid Markdown file with clusters + gaps + questions

# 4. Frontend
# → GapPanel shows short labels
# → "Find Papers" → paper cards
# → "Export Report" → file download
```

---

## Technical Risks & Mitigations

| Risk | Probability | Mitigation |
|------|-------------|-----------|
| LLM label latency (blocking refresh) | Medium | 5s timeout + 3-tier fallback; labels are cached in DB |
| Semantic Scholar rate limit on recommendations | Medium | Reuse existing rate limiter; limit=5 keeps requests small |
| Bridge candidates are UUIDs not keywords | Low | Use `cluster_a_names`/`cluster_b_names` from DB (already human-readable) |
| Export endpoint returns empty report | Low | Check for data before generating; return 404 with actionable message |
| GapPanel re-renders on recommendation state | Low | Use `useCallback` for handlers; recommendations stored per-gap in Record |

---

## Portfolio Demo Flow (v0.12.0)

```
1. Zotero에서 논문 34편 임포트 (이미 완료)
2. 3D 그래프에서 지식 지형도 탐색
   → "469개 개념, 4170개 관계를 자동 추출했습니다"
3. Topics 뷰로 전환 → 클러스터 구조 확인
   → "AI Trust & Adoption", "Algorithmic HRM" 등 명확한 토픽 레이블  ← Phase 1
4. Gaps 뷰로 전환 → 연구 갭 탐지
   → "10개 구조적 갭을 발견했고, AI가 연구 질문을 생성했습니다"
5. "Find Papers" 클릭 → 갭을 잇는 논문 5편 자동 추천  ← Phase 2
   → "Semantic Scholar에서 브릿지 개념 기반으로 추천합니다"
6. "Export Report" 클릭 → 갭 분석 리포트 다운로드  ← Phase 3
   → "이 리포트를 연구 프로포절에 바로 활용할 수 있습니다"
```
